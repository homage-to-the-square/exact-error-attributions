{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba97c6eb-8eb8-4b78-b450-28c06ea183cc",
   "metadata": {},
   "source": [
    "How the simulation is done:\n",
    "- First, a base simulation is done per sample size.\n",
    "- Then, as needed, more simulations are done by upticking the iteration values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c011f0",
   "metadata": {},
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0bad1c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:25:38.022149Z",
     "iopub.status.busy": "2025-07-17T16:25:38.022149Z",
     "iopub.status.idle": "2025-07-17T16:25:38.277499Z",
     "shell.execute_reply": "2025-07-17T16:25:38.277499Z",
     "shell.execute_reply.started": "2025-07-17T16:25:38.022149Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from itertools import permutations\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c60867f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:25:38.278004Z",
     "iopub.status.busy": "2025-07-17T16:25:38.278004Z",
     "iopub.status.idle": "2025-07-17T16:25:38.893298Z",
     "shell.execute_reply": "2025-07-17T16:25:38.893298Z",
     "shell.execute_reply.started": "2025-07-17T16:25:38.278004Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import statsmodels.api as sm\n",
    "from collections import defaultdict\n",
    "from scipy.special import expit, logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8e344f9-2ced-489a-8e10-f7857eec9428",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:25:38.893298Z",
     "iopub.status.busy": "2025-07-17T16:25:38.893298Z",
     "iopub.status.idle": "2025-07-17T16:25:38.895719Z",
     "shell.execute_reply": "2025-07-17T16:25:38.895719Z",
     "shell.execute_reply.started": "2025-07-17T16:25:38.893298Z"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84b6156-c90f-4033-9c5e-0159b8bc39b7",
   "metadata": {},
   "source": [
    "# Helper Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67519016-2ee3-4fe8-a941-333ade9e92dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:25:38.895719Z",
     "iopub.status.busy": "2025-07-17T16:25:38.895719Z",
     "iopub.status.idle": "2025-07-17T16:25:38.902232Z",
     "shell.execute_reply": "2025-07-17T16:25:38.902232Z",
     "shell.execute_reply.started": "2025-07-17T16:25:38.895719Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from ddc_utils import *\n",
    "from data_generating_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8154912-76fc-423e-8804-d10917fb6b00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:25:38.903297Z",
     "iopub.status.busy": "2025-07-17T16:25:38.903297Z",
     "iopub.status.idle": "2025-07-17T16:25:38.906812Z",
     "shell.execute_reply": "2025-07-17T16:25:38.906812Z",
     "shell.execute_reply.started": "2025-07-17T16:25:38.903297Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_pickle_obj(file_path, raw_data):\n",
    "    with open(file_path, \"wb\") as handle:\n",
    "        pickle.dump(raw_data, handle)\n",
    "\n",
    "def read_pickle_obj(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bfdd51",
   "metadata": {},
   "source": [
    "# Hyperparams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f1fc130",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:25:38.907812Z",
     "iopub.status.busy": "2025-07-17T16:25:38.907812Z",
     "iopub.status.idle": "2025-07-17T16:25:38.909813Z",
     "shell.execute_reply": "2025-07-17T16:25:38.909813Z",
     "shell.execute_reply.started": "2025-07-17T16:25:38.907812Z"
    }
   },
   "outputs": [],
   "source": [
    "pop_index = 1\n",
    "iter_val = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4ae7e04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:25:38.909813Z",
     "iopub.status.busy": "2025-07-17T16:25:38.909813Z",
     "iopub.status.idle": "2025-07-17T16:25:38.913801Z",
     "shell.execute_reply": "2025-07-17T16:25:38.913801Z",
     "shell.execute_reply.started": "2025-07-17T16:25:38.909813Z"
    }
   },
   "outputs": [],
   "source": [
    "rand_generator = np.random.default_rng(seed=333 * pop_index + iter_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29d053a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:25:38.914805Z",
     "iopub.status.busy": "2025-07-17T16:25:38.913801Z",
     "iopub.status.idle": "2025-07-17T16:25:38.919140Z",
     "shell.execute_reply": "2025-07-17T16:25:38.919140Z",
     "shell.execute_reply.started": "2025-07-17T16:25:38.914805Z"
    }
   },
   "outputs": [],
   "source": [
    "population_size = 100_000\n",
    "number_of_coefficients = 1\n",
    "\n",
    "num_iters_per_population_for_small_samples = 25_000\n",
    "num_iters_per_population_for_large_samples = 10_000\n",
    "small_large_sample_co = 100\n",
    "\n",
    "# biased sampling scheme params:\n",
    "sample_probability_centering = 0.77\n",
    "sample_probability_bias_factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b26197b3-5f53-4dac-b841-377c94b91820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:25:38.919140Z",
     "iopub.status.busy": "2025-07-17T16:25:38.919140Z",
     "iopub.status.idle": "2025-07-17T16:25:38.923486Z",
     "shell.execute_reply": "2025-07-17T16:25:38.923486Z",
     "shell.execute_reply.started": "2025-07-17T16:25:38.919140Z"
    }
   },
   "outputs": [],
   "source": [
    "ALL_SAMPLE_SIZES = (\n",
    "    # [3, 4, 5] + \n",
    "    [6, 7, 9, 11, 13, 16, 20, 25]\n",
    "    # + [i for i in range(30, 45)]\n",
    "    # + [50, 70, 100, 150, 250, 400, 600, 1000, 1400]\n",
    "    # + [2000, 3000, 5000, 7500, 10_000, 15_000, 20_000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e03bb99e-8774-4699-94ed-c7e13d2b7804",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:25:38.923486Z",
     "iopub.status.busy": "2025-07-17T16:25:38.923486Z",
     "iopub.status.idle": "2025-07-17T16:25:38.927370Z",
     "shell.execute_reply": "2025-07-17T16:25:38.927370Z",
     "shell.execute_reply.started": "2025-07-17T16:25:38.923486Z"
    }
   },
   "outputs": [],
   "source": [
    "njobs = 3\n",
    "multiprocess_backend = \"loky\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaf423c-f86f-4d93-852e-192c32fa219c",
   "metadata": {},
   "source": [
    "# Load Finite Population Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bd16c32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:25:38.927370Z",
     "iopub.status.busy": "2025-07-17T16:25:38.927370Z",
     "iopub.status.idle": "2025-07-17T16:25:38.930848Z",
     "shell.execute_reply": "2025-07-17T16:25:38.930848Z",
     "shell.execute_reply.started": "2025-07-17T16:25:38.927370Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle_filename = f'base_population_data_Logit_1.pickle'\n",
    "pop_data = pd.read_pickle(pickle_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25216b90",
   "metadata": {},
   "source": [
    "# Run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c9b81a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:25:38.931851Z",
     "iopub.status.busy": "2025-07-17T16:25:38.930848Z",
     "iopub.status.idle": "2025-07-17T16:25:38.933955Z",
     "shell.execute_reply": "2025-07-17T16:25:38.933955Z",
     "shell.execute_reply.started": "2025-07-17T16:25:38.931851Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_cols = [f'x_{i}' for i in range(number_of_coefficients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65af24c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:25:38.933955Z",
     "iopub.status.busy": "2025-07-17T16:25:38.933955Z",
     "iopub.status.idle": "2025-07-17T16:25:38.938497Z",
     "shell.execute_reply": "2025-07-17T16:25:38.938497Z",
     "shell.execute_reply.started": "2025-07-17T16:25:38.933955Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_specific_non_separable_count = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b506e88",
   "metadata": {},
   "source": [
    "#### get population-level statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c217fb9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:25:38.938497Z",
     "iopub.status.busy": "2025-07-17T16:25:38.938497Z",
     "iopub.status.idle": "2025-07-17T16:25:38.961974Z",
     "shell.execute_reply": "2025-07-17T16:25:38.961974Z",
     "shell.execute_reply.started": "2025-07-17T16:25:38.938497Z"
    }
   },
   "outputs": [],
   "source": [
    "pop_x = pop_data[feature_cols]\n",
    "pop_y = pop_data['y']\n",
    "\n",
    "pop_model = sm.Logit(endog = pop_y, exog = pop_x).fit(disp=0)\n",
    "pop_beta = np.array(pop_model.params)\n",
    "pop_gs = pop_x * (np.array(pop_y).reshape((population_size, 1)) - \\\n",
    "              np.array(pop_model.predict()).reshape((population_size, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e44da0",
   "metadata": {},
   "source": [
    "#### actually run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "745b72c7-d886-4c27-9460-5b198291bad9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:25:38.962480Z",
     "iopub.status.busy": "2025-07-17T16:25:38.962480Z",
     "iopub.status.idle": "2025-07-17T16:25:38.966334Z",
     "shell.execute_reply": "2025-07-17T16:25:38.966334Z",
     "shell.execute_reply.started": "2025-07-17T16:25:38.962480Z"
    }
   },
   "outputs": [],
   "source": [
    "def fn_to_parallel(pop_data, temp_sample_size):\n",
    "    obtained_valid_sample = False\n",
    "    non_separable_count = 0\n",
    "    while not obtained_valid_sample:\n",
    "        # intended sample:\n",
    "        pop_data[\"r0\"] = 0\n",
    "        pop_data.loc[\n",
    "            np.random.choice(pop_data.index, size=temp_sample_size, replace=False),\n",
    "            \"r0\",\n",
    "        ] = 1\n",
    "\n",
    "        full_sampled_data = pop_data[pop_data[\"r0\"] == 1]\n",
    "\n",
    "        # biased sample:\n",
    "        pop_data[\"r\"] = 0\n",
    "\n",
    "        marginal_probabilities = expit(\n",
    "            logit(sample_probability_centering)\n",
    "            + sample_probability_bias_factor\n",
    "            * (2 * full_sampled_data[\"y\"] - 1)\n",
    "            * full_sampled_data[\"x_0\"]\n",
    "        )\n",
    "        other_sample_indices = marginal_probabilities.index[\n",
    "            rand_generator.binomial(n=1, p=marginal_probabilities) == 1\n",
    "        ]\n",
    "        pop_data.loc[other_sample_indices, \"r\"] = 1\n",
    "\n",
    "        # sample_data here means the biased sample data.\n",
    "        sample_data = pop_data[pop_data[\"r\"] == 1]\n",
    "\n",
    "        # if the sample size is too small, check for seperability:\n",
    "        realised_sample_size = len(other_sample_indices)\n",
    "        if realised_sample_size < 1_000:\n",
    "            if is_binomial_data_seperable(sample_data, \"y\", \"x_0\"):\n",
    "                non_separable_count = non_separable_count + 1\n",
    "                continue\n",
    "\n",
    "        obtained_valid_sample = True\n",
    "\n",
    "    \"\"\"\n",
    "        Then, compute the logistic betas, ddc, Jns:\n",
    "    \"\"\"\n",
    "    # compute biased x, y, model, beta\n",
    "    sample_x, sample_y = sample_data[feature_cols], sample_data[\"y\"]\n",
    "    sample_beta = np.array(\n",
    "        sm.Logit(endog=sample_y, exog=sample_x).fit(disp=0, maxiter=5_00).params\n",
    "    )\n",
    "    sample_r = pop_data[\"r\"]\n",
    "\n",
    "    # compute full x, y, model, beta\n",
    "    sample_x_full, sample_y_full = (\n",
    "        full_sampled_data[feature_cols],\n",
    "        full_sampled_data[\"y\"],\n",
    "    )\n",
    "    sample_beta_full = np.array(\n",
    "        sm.Logit(endog=sample_y_full, exog=sample_x_full)\n",
    "        .fit(disp=0, maxiter=5_00)\n",
    "        .params\n",
    "    )\n",
    "    sample_r_full = pop_data[\"r0\"]\n",
    "\n",
    "    # ret: sample beta, sample ddc, sample Jn, sample size; intended beta, intended ddc, intended Jn, non seperable count\n",
    "    return (\n",
    "        pd.Series(sample_beta),\n",
    "        pop_gs.corrwith(sample_r)[[\"x_0\"]],\n",
    "        compute_average_jn(\n",
    "            pop_beta, sample_beta, sample_x, sample_y, model_type=\"Logit\"\n",
    "        ),\n",
    "        realised_sample_size,\n",
    "        pd.Series(sample_beta_full),\n",
    "        pop_gs.corrwith(sample_r_full)[[\"x_0\"]],\n",
    "        compute_average_jn(\n",
    "            pop_beta,\n",
    "            sample_beta_full,\n",
    "            sample_x_full,\n",
    "            sample_y_full,\n",
    "            model_type=\"Logit\",\n",
    "        ),\n",
    "        non_separable_count,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "260fd510",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T16:25:38.967338Z",
     "iopub.status.busy": "2025-07-17T16:25:38.966334Z",
     "iopub.status.idle": "2025-07-17T16:40:12.674609Z",
     "shell.execute_reply": "2025-07-17T16:40:12.674609Z",
     "shell.execute_reply.started": "2025-07-17T16:25:38.967338Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/8 [00:00<?, ?it/s]\n",
      "\u001b[A [00:00, ?it/s]\n",
      "\u001b[A0it [00:10, 166.83it/s]\n",
      "\u001b[A4it [00:20, 175.64it/s]\n",
      "\u001b[A8it [00:30, 181.05it/s]\n",
      "\u001b[A0it [00:40, 186.00it/s]\n",
      "\u001b[A8it [00:50, 189.23it/s]\n",
      "\u001b[A88it [01:01, 187.13it/s]\n",
      "\u001b[A21it [01:11, 182.79it/s]\n",
      "\u001b[A38it [01:21, 182.43it/s]\n",
      "\u001b[A74it [01:31, 185.63it/s]\n",
      "\u001b[A03it [01:42, 185.97it/s]\n",
      "\u001b[A71it [01:52, 183.65it/s]\n",
      "\u001b[A22it [02:02, 184.03it/s]\n",
      "25000it [02:15, 183.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of non-seperable samples for sample size 6: 34800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▍                                                                        | 1/8 [02:17<16:02, 137.52s/it]\n",
      "\u001b[A [00:00, ?it/s]\n",
      "\u001b[A9it [00:10, 213.02it/s]\n",
      "\u001b[A0it [00:20, 208.64it/s]\n",
      "\u001b[A3it [00:30, 211.74it/s]\n",
      "\u001b[A8it [00:40, 212.85it/s]\n",
      "\u001b[A47it [00:50, 213.46it/s]\n",
      "\u001b[A93it [01:01, 208.76it/s]\n",
      "\u001b[A51it [01:11, 210.47it/s]\n",
      "\u001b[A59it [01:21, 213.20it/s]\n",
      "\u001b[A83it [01:31, 215.82it/s]\n",
      "\u001b[A83it [01:42, 215.82it/s]\n",
      "\u001b[A11it [01:42, 206.41it/s]\n",
      "25000it [01:58, 211.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of non-seperable samples for sample size 7: 23259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▊                                                              | 2/8 [04:17<12:44, 127.34s/it]\n",
      "\u001b[A [00:00, ?it/s]\n",
      "\u001b[A3it [00:10, 235.45it/s]\n",
      "\u001b[A7it [00:20, 240.98it/s]\n",
      "\u001b[A6it [00:30, 241.95it/s]\n",
      "\u001b[A7it [00:41, 231.54it/s]\n",
      "\u001b[A27it [00:51, 231.55it/s]\n",
      "\u001b[A43it [01:01, 231.55it/s]\n",
      "\u001b[A59it [01:11, 230.63it/s]\n",
      "\u001b[A47it [01:22, 223.08it/s]\n",
      "\u001b[A27it [01:32, 224.27it/s]\n",
      "25000it [01:48, 230.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of non-seperable samples for sample size 9: 12786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████▏                                                   | 3/8 [06:08<09:58, 119.60s/it]\n",
      "\u001b[A [00:00, ?it/s]\n",
      "\u001b[A5it [00:10, 238.54it/s]\n",
      "\u001b[A1it [00:20, 237.39it/s]\n",
      "\u001b[A5it [00:30, 242.32it/s]\n",
      "\u001b[A7it [00:40, 244.07it/s]\n",
      "\u001b[A31it [00:50, 248.80it/s]\n",
      "\u001b[A04it [01:01, 243.77it/s]\n",
      "\u001b[A19it [01:11, 246.23it/s]\n",
      "\u001b[A34it [01:21, 247.74it/s]\n",
      "\u001b[A45it [01:31, 245.29it/s]\n",
      "25000it [01:43, 242.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of non-seperable samples for sample size 11: 7329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 4/8 [07:52<07:34, 113.63s/it]\n",
      "\u001b[A [00:00, ?it/s]\n",
      "\u001b[A5it [00:10, 237.11it/s]\n",
      "\u001b[A1it [00:20, 248.68it/s]\n",
      "\u001b[A0it [00:30, 245.96it/s]\n",
      "\u001b[A39it [00:40, 250.19it/s]\n",
      "\u001b[A15it [00:50, 252.24it/s]\n",
      "\u001b[A75it [01:01, 245.22it/s]\n",
      "\u001b[A35it [01:11, 248.17it/s]\n",
      "\u001b[A80it [01:22, 248.62it/s]\n",
      "25000it [01:40, 249.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of non-seperable samples for sample size 13: 4490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████████████▉                               | 5/8 [09:34<05:28, 109.43s/it]\n",
      "\u001b[A [00:00, ?it/s]\n",
      "\u001b[A3it [00:10, 244.12it/s]\n",
      "\u001b[A9it [00:20, 256.44it/s]\n",
      "\u001b[A9it [00:30, 263.43it/s]\n",
      "\u001b[A37it [00:40, 257.34it/s]\n",
      "\u001b[A43it [00:50, 261.76it/s]\n",
      "\u001b[A42it [01:01, 263.89it/s]\n",
      "\u001b[A23it [01:11, 257.85it/s]\n",
      "\u001b[A55it [01:22, 261.82it/s]\n",
      "25000it [01:35, 262.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of non-seperable samples for sample size 16: 2339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████▎                    | 6/8 [11:11<03:30, 105.30s/it]\n",
      "\u001b[A [00:00, ?it/s]\n",
      "\u001b[A7it [00:10, 249.83it/s]\n",
      "\u001b[A3it [00:20, 262.43it/s]\n",
      "\u001b[A5it [00:30, 264.21it/s]\n",
      "\u001b[A19it [00:42, 247.91it/s]\n",
      "\u001b[A07it [00:52, 254.94it/s]\n",
      "\u001b[A59it [01:02, 261.40it/s]\n",
      "\u001b[A05it [01:13, 254.32it/s]\n",
      "\u001b[A67it [01:23, 257.20it/s]\n",
      "25000it [01:36, 258.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of non-seperable samples for sample size 20: 939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████████████████████████████████████████████████████████████████████▋          | 7/8 [12:50<01:43, 103.18s/it]\n",
      "\u001b[A [00:00, ?it/s]\n",
      "\u001b[A5it [00:10, 263.36it/s]\n",
      "\u001b[A9it [00:20, 255.93it/s]\n",
      "\u001b[A5it [00:30, 262.63it/s]\n",
      "\u001b[A5it [00:40, 262.63it/s]\n",
      "\u001b[A99it [00:40, 263.63it/s]\n",
      "\u001b[A67it [00:50, 253.78it/s]\n",
      "\u001b[A67it [00:50, 253.78it/s]\n",
      "\u001b[A67it [01:00, 253.78it/s]\n",
      "\u001b[A59it [01:00, 255.40it/s]\n",
      "\u001b[A59it [01:10, 255.40it/s]\n",
      "\u001b[A67it [01:10, 243.45it/s]\n",
      "\u001b[A56it [01:21, 234.37it/s]\n",
      "25000it [01:41, 245.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of non-seperable samples for sample size 25: 303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 8/8 [14:33<00:00, 109.21s/it]\n"
     ]
    }
   ],
   "source": [
    "for temp_sample_size in tqdm(ALL_SAMPLE_SIZES):\n",
    "    # set up how much to sample for this population:\n",
    "    if temp_sample_size < small_large_sample_co:\n",
    "        num_iters_per_population = num_iters_per_population_for_small_samples\n",
    "    else:\n",
    "        num_iters_per_population = num_iters_per_population_for_large_samples\n",
    "\n",
    "    # run all the results, with the function to parallel above!\n",
    "    agg_results = list(\n",
    "        tqdm(\n",
    "            Parallel(n_jobs=njobs, backend=multiprocess_backend, return_as=\"generator\")(\n",
    "                delayed(fn_to_parallel)(pop_data, temp_sample_size)\n",
    "                for rep in range(num_iters_per_population)\n",
    "            ),\n",
    "            mininterval=10,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    sample_specific_non_separable_count[temp_sample_size] = np.sum(pd.Series([temp_res[7] for temp_res in agg_results]))\n",
    "    print(f'# of non-seperable samples for sample size {temp_sample_size}: {sample_specific_non_separable_count[temp_sample_size]}')\n",
    "    \n",
    "    \"\"\"\n",
    "        Save the data!\n",
    "    \"\"\"\n",
    "    # concatenate the biased versions:\n",
    "    temp_samp_beta_biased = pd.Series([temp_res[0][0] for temp_res in agg_results])\n",
    "    temp_ddc_biased = pd.Series([temp_res[1].iloc[0] for temp_res in agg_results])\n",
    "    temp_jn_biased = pd.Series([temp_res[2][0].iloc[0] for temp_res in agg_results])\n",
    "    realised_sizes = pd.Series([temp_res[3] for temp_res in agg_results])\n",
    "\n",
    "    # concat the SRS versions:\n",
    "    temp_samp_beta_full = pd.Series([temp_res[4][0] for temp_res in agg_results])\n",
    "    temp_ddc_full = pd.Series([temp_res[5].iloc[0] for temp_res in agg_results])\n",
    "    temp_jn_full = pd.Series([temp_res[6][0].iloc[0] for temp_res in agg_results])\n",
    "\n",
    "    temp_ss_data = pd.concat(\n",
    "        [\n",
    "            temp_samp_beta_biased,\n",
    "            temp_ddc_biased,\n",
    "            temp_jn_biased,\n",
    "            realised_sizes,\n",
    "            temp_samp_beta_full,\n",
    "            temp_ddc_full,\n",
    "            temp_jn_full,\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    temp_ss_data.columns = [\n",
    "        \"samp_biased\",\n",
    "        \"ddc_biased\",\n",
    "        \"jn_biased\",\n",
    "        \"realized_size_biased\",\n",
    "        \"samp_intended\",\n",
    "        \"ddc_intended\",\n",
    "        \"jn_intended\",\n",
    "    ]\n",
    "\n",
    "    temp_ss_data[\"sample_size\"] = temp_sample_size\n",
    "    temp_ss_data[\"pop_beta\"] = pop_beta[0]\n",
    "\n",
    "    temp_ss_data[\"mse_biased\"] = (\n",
    "        temp_ss_data[\"pop_beta\"] - temp_ss_data[\"samp_biased\"]\n",
    "    ) ** 2\n",
    "\n",
    "    temp_ss_data[\"mse_intended\"] = (\n",
    "        temp_ss_data[\"pop_beta\"] - temp_ss_data[\"samp_intended\"]\n",
    "    ) ** 2\n",
    "\n",
    "    to_pickle_obj(f\"sim_results/sim_{temp_sample_size}_iter_{iter_val}.pickle\", temp_ss_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d50f74a-8f5c-4741-bedd-93ad9cbd4969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
